{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import os\n",
    "import difflib\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import validators\n",
    "import gdown\n",
    "from urllib.parse import parse_qs\n",
    "def cleaning(data):\n",
    "        clean_col_names = []\n",
    "        for col in data.columns:\n",
    "            clean_col = re.sub(r'[_\\-]', ' ', col)\n",
    "            clean_col = re.sub(r'(?<!^)(?=[A-Z])', ' ', col)\n",
    "            clean_col = clean_col.strip()\n",
    "            clean_col = clean_col.replace('_', ' ')\n",
    "            clean_col = re.sub(r'\\s+', ' ', clean_col)\n",
    "            clean_col = clean_col.lower()# Improved regex for better name cleaning\n",
    "            clean_col_names.append(clean_col)\n",
    "        data.columns = clean_col_names\n",
    "        return data\n",
    "def extract_file_id(drive_link):\n",
    "        \"\"\"Extracts the file ID from a Google Drive link.\"\"\"\n",
    "        file_id = None\n",
    "        try:\n",
    "            parsed = urlparse(drive_link)\n",
    "            file_id = drive_link.split(\"/\")[5]\n",
    "            filename = os.path.basename(parsed.path)\n",
    "        except IndexError:\n",
    "            print(\"Invalid Google Drive link provided.\")\n",
    "        return file_id\n",
    "\n",
    "def download_file(file_id):\n",
    "        \"\"\"Downloads the file from Google Drive.\"\"\"\n",
    "        download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        response = requests.get(download_url)\n",
    "        return response.content\n",
    "\n",
    "def load_data():\n",
    "        print(\"How would you like to input the data?\")\n",
    "        print(\"1. Browse from system\")\n",
    "        print(\"2. Provide a link to online data\")\n",
    "        choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "        if choice == '1':\n",
    "            root = tk.Tk()\n",
    "            root.withdraw()  # Hide the main window\n",
    "            file_path = filedialog.askopenfilename()  # Open file dialog\n",
    "\n",
    "            if file_path:\n",
    "                try:\n",
    "                    # Detect file type and read accordingly\n",
    "                    file_ext = os.path.splitext(file_path)[-1].lower()\n",
    "                    if file_ext == '.csv' or file_ext in ['.xls', '.xlsx']:\n",
    "                        if file_ext == '.csv':\n",
    "                            with open(file_path, 'r') as file:\n",
    "                                first_line = file.readline()\n",
    "                                separator = re.search(\"[,;\\t]\", first_line).group()\n",
    "                            data = pd.read_csv(file_path, sep=separator)\n",
    "                        else:\n",
    "                            data = pd.read_excel(file_path)\n",
    "                    else:\n",
    "                        print(\"Unsupported file format. Please provide a CSV, XLS, or XLSX file.\")\n",
    "                        return None, None,None\n",
    "                    # Check if data has any columns\n",
    "                    if len(data.columns) == 0:\n",
    "                        print(\"Error: The file contains no columns.\")\n",
    "                        return None, None,None\n",
    "\n",
    "                    # Clean column names\n",
    "                    data = cleaning(data)\n",
    "\n",
    "                    # Extract filename and get dataset name confirmation\n",
    "                    filename = os.path.basename(file_path)\n",
    "                    dataset_name = filename\n",
    "                    #confirm_name = input(f\"Is '{filename}' the intended dataset name? (yes/no): \")\n",
    "                    #dataset_name = filename if confirm_name.lower() == 'yes' else input(\"Enter the dataset name: \")\n",
    "                    #target_variable, data = targeted_variable(data)  # Capture the returned value from target_variable function\n",
    "                    target_variable = get_target_variables(data, dataset_name)\n",
    "                    return data, dataset_name, target_variable\n",
    "                    \n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"Error:\", e)\n",
    "                    return None, None,None\n",
    "\n",
    "            else:\n",
    "                print(\"No file selected.\")\n",
    "                return None, None,None\n",
    "\n",
    "        elif choice == '2':\n",
    "            url = input(\"Enter the URL of the online data: \")\n",
    "            if not validators.url(url):\n",
    "                print(\"Invalid URL. Please check the URL and try again.\")\n",
    "                return None, None,None\n",
    "            try:\n",
    "                data = None\n",
    "                if 'drive.google.com' in url:\n",
    "                    # Google Drive URL\n",
    "                    try:\n",
    "                        file_id = extract_file_id(url)\n",
    "                        if file_id is not None:\n",
    "                            file_content = download_file(file_id)\n",
    "                            # Try reading the file\n",
    "                            try:\n",
    "                                data = pd.read_csv(io.StringIO(file_content.decode('utf-8')))\n",
    "                            except pd.errors.ParserError:\n",
    "                                try:\n",
    "                                    data = pd.read_excel(io.BytesIO(file_content))\n",
    "                                except Exception as e:\n",
    "                                    print(\"Unsupported file format. Please provide a CSV, XLS, or XLSX file.\")\n",
    "                                    return None, None,None\n",
    "                        else:\n",
    "                            print(\"Invalid Google Drive URL. The URL should contain an 'id' parameter.\")\n",
    "                            return None, None,None\n",
    "                    except Exception as e:\n",
    "                        print(\"Error:\", e)\n",
    "                        print(\"An error occurred. Please check the URL and try again.\")\n",
    "                        return None, None,None\n",
    "\n",
    "                else:\n",
    "                    # Other URL\n",
    "                    response = requests.get(url)\n",
    "                    if url.endswith('.csv'):\n",
    "                        data = pd.read_csv(BytesIO(response.content))\n",
    "                    elif url.endswith('.xls') or url.endswith('.xlsx'):\n",
    "                        data = pd.read_excel(BytesIO(response.content))\n",
    "                    else:\n",
    "                        print(\"Unsupported file format. Please provide a CSV, XLS, or XLSX file.\")\n",
    "                        return None, None,None\n",
    "                # Clean column names\n",
    "                data = cleaning(data)\n",
    "\n",
    "                # Check if data has any columns\n",
    "                if len(data.columns) == 0:\n",
    "                    print(\"Error: The online data contains no columns.\")\n",
    "                    return None, None,None\n",
    "                path = urlparse(url).path\n",
    "                filename = os.path.basename(path)\n",
    "                dataset_name = filename\n",
    "                target_variable = get_target_variables(data, dataset_name)\n",
    "                return data, dataset_name, target_variable\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "                print(\"An error occurred. Please check the URL and try again.\")\n",
    "                return None, None,None\n",
    "        else:\n",
    "            print(\"No file selected.\")\n",
    "            return None, None,None\n",
    "        \n",
    "###\n",
    "\n",
    "def get_target_variables(data,dataset_name):\n",
    "                # Load the dataset\n",
    "                # Get basic information about the dataset\n",
    "                df = pd.DataFrame(data)\n",
    "                num_records = len(df)\n",
    "                num_features = len(df.columns)\n",
    "                feature_names = [str(name) for name in df.columns.tolist()]  # Convert feature names to strings\n",
    "                data_types = df.dtypes.tolist()\n",
    "                data_types_str = [str(dtype) for dtype in data_types]\n",
    "                missing_values = df.isnull().sum().tolist()\n",
    "                dataset_shape = df.shape       \n",
    "                \n",
    "                # Generate a brief introduction using GPT API\n",
    "                prompt = f\"this is a dataset of {dataset_name} and overall shape of dataset is {dataset_shape}.The dataset contains {num_records} records and {num_features} features. The features include: {', '.join(feature_names)}. The data types of features are: {', '.join(map(str, data_types_str))}.\"\n",
    "                prompt += f\"Here are the summary statistics:\\n{df.describe(include='all')}\"\n",
    "                prompt += f\" Please provide most possible target varaible (only one) of dataset return in a only a single string.\"\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "                    max_tokens=200,\n",
    "                    temperature=0.7,\n",
    "                    top_p=1.0,\n",
    "                    frequency_penalty=0.0,\n",
    "                    presence_penalty=0.0\n",
    "                )\n",
    "                # Print the generated introduction\n",
    "                target_variable = (response.choices[0].message.content)\n",
    "                # If the response is not a string, convert it to a string\n",
    "                if not isinstance(target_variable, str):\n",
    "                    target_variable = str(target_variable)\n",
    "                if target_variable:\n",
    "                    print(\"Target variables found:\", target_variable)\n",
    "                else:\n",
    "                    print(\"No target variables found.\")\n",
    "                    target_variable = None\n",
    "                return target_variable\n",
    "data, dataset_name, target_variable = load_data()\n",
    "print(data)\n",
    "print(dataset_name)\n",
    "print(target_variable)\n",
    "df = pd.DataFrame(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BivariateAnalyzer1:\n",
    "    def __init__(self, df, dataset_name):\n",
    "        self.df = df\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "    def analyze(self):\n",
    "        analysis_results = {}\n",
    "        for column1 in self.df.columns:\n",
    "            for column2 in self.df.columns:\n",
    "                if column1 != column2:\n",
    "                    result = self.analyze_columns(column1, column2)\n",
    "                    if result is not None:\n",
    "                        analysis_results[(column1, column2)] = result\n",
    "        return analysis_results\n",
    "\n",
    "    def analyze_columns(self, column1, column2):\n",
    "        series1 = self.df[column1]\n",
    "        series2 = self.df[column2]\n",
    "        if pd.api.types.is_numeric_dtype(series1) and pd.api.types.is_numeric_dtype(series2):\n",
    "            correlation = series1.corr(series2)\n",
    "            return {'correlation': correlation}\n",
    "        elif pd.api.types.is_numeric_dtype(series1) and pd.api.types.is_categorical_dtype(series2):\n",
    "            grouped_mean = series1.groupby(series2).mean()\n",
    "            return {'grouped_mean': grouped_mean}\n",
    "        elif pd.api.types.is_categorical_dtype(series1) and pd.api.types.is_numeric_dtype(series2):\n",
    "            grouped_mean = series2.groupby(series1).mean()\n",
    "            return {'grouped_mean': grouped_mean}\n",
    "        elif pd.api.types.is_categorical_dtype(series1) and pd.api.types.is_categorical_dtype(series2):\n",
    "            unique_combinations = self.df.groupby([series1.name, series2.name]).size()\n",
    "            return {'unique_combinations': unique_combinations}\n",
    "\n",
    "analyzer = BivariateAnalyzer1(df, 'dataset_name')\n",
    "analysis_results = analyzer.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def bi_poss_corr(df, dataset_name, target_variable, analysis_results):\n",
    "    dataset_columns = df.columns.tolist()\n",
    "    data_types = df.dtypes.tolist()\n",
    "    max_unique_values = 10\n",
    "    unique_counts = df.nunique()\n",
    "    object_columns = {}\n",
    "    length = len(df.columns)\n",
    "    length = 2 * length\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].unique().tolist()\n",
    "        if len(unique_values) > max_unique_values:\n",
    "            unique_values = random.sample(unique_values, max_unique_values)\n",
    "            object_columns[col] = unique_values\n",
    "        prompt = (\n",
    "            f\"In the {dataset_name} dataset, perform a bivariate analysis with the target variable '{target_variable}'. \"\n",
    "            f\"Return a dictionary of at least {length} column pairs, where each pair of columns should be the target variable '{target_variable}'. \"\n",
    "            f\"Use the correlations {analysis_results} to select pairs. \"\n",
    "            f\"Include pairs with the most positive, most negative, and neutral correlations. \"\n",
    "            f\"Format each pair as 'column1':'column2'. \"\n",
    "            f\"Use full, case-sensitive, and unique variable names. \"\n",
    "            f\"Avoid syntax errors and do not include the correlation value in the output. \"\n",
    "            f\"Focus on correlation (most positive, most negative and balanced) the target variable with as many other variables as possible.\"\n",
    "            f\"each column will pair with at least 3 other columns except target_variable\"\n",
    "            f\"Output format of your will be a dictionary with the format {{\\column\\ : \\column\\, \\column\\ : \\column\\}} only.\"\n",
    "            )\n",
    "        print(prompt)\n",
    "        response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "                max_tokens=2000,\n",
    "                temperature=0.7,\n",
    "                top_p=0.7,\n",
    "                frequency_penalty=0.0,\n",
    "                presence_penalty=0.0\n",
    "            )\n",
    "            \n",
    "            # Parse the generated response into dictionary format\n",
    "        response_content = response.choices[0].message.content\n",
    "        try:\n",
    "            # Remove the outer double quotes and newline characters\n",
    "            response_content = response_content.strip('\"\\n')\n",
    "            # Replace curly braces with square brackets to convert dictionary to list\n",
    "            response_content = response_content.replace('{', '[').replace('}', ']')\n",
    "            # Split the string into lines\n",
    "            lines = response_content.split(',')\n",
    "            bi_columns = [{line.strip().split(':')[0].strip().strip('\"\\n[').strip(\"'\"): line.strip().split(':')[1].strip().strip('\"\\n]').strip(\"'\")} for line in lines if ':' in line]            for i in range(len(bi_columns)):\n",
    "                for key, value in bi_columns[i].items():\n",
    "                    # Remove the quotes from the key and value\n",
    "                    new_key = key.strip(\"'\")\n",
    "                    new_value = value.strip(\"'\")\n",
    "                    # Update the dictionary with the new key and value\n",
    "                    bi_columns[i] = {new_key: new_value}            \n",
    "            return bi_columns\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            return None\n",
    "bi_columns = bi_poss_corr(df,dataset_name,target_variable,analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_analyze(df, dataset_name, bi_columns, analysis_results):\n",
    "    bi_descriptions = {} \n",
    "    max_unique_values = 10\n",
    "    object_columns={}\n",
    "    for col in df.columns:\n",
    "                unique_values = df[col].unique().tolist()\n",
    "                if len(unique_values) > max_unique_values:\n",
    "                    unique_values = random.sample(unique_values, max_unique_values)\n",
    "                    object_columns[col] = unique_values\n",
    "    for bi_column in bi_columns:\n",
    "        for column1, column2 in bi_column.items():\n",
    "            uni1 = object_columns.get(column1)\n",
    "            uni2 = object_columns.get(column2)\n",
    "            stats = analysis_results.get((column1, column2), {})\n",
    "            prompt = f\"these are unique values in {column1} {uni1} and {column2} {uni2} in the dataset. Please generate a description only about the relationship (for bivariate analysis) between {column1} and {column2}  by using {stats} in simple words or in natural language for my Graph. Start with explaining their relationship and how to they are related only and don't describe about dataset starts with the relationship between these columns are tend to be like that. Don't return all the unique values of columns that are given thats are only for reference. \"\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "                max_tokens=300,\n",
    "                temperature=0.2,\n",
    "                top_p=1.0,\n",
    "                frequency_penalty=0.0,\n",
    "                presence_penalty=0.0\n",
    "            )\n",
    "            \n",
    "            bi_descriptions[(column1, column2)] = response.choices[0].message.content\n",
    "            \n",
    "\n",
    "    return bi_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_gpt = bi_analyze(df, dataset_name, bi_columns, analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BivariateAnalyzer:\n",
    "    def __init__(self, df, bi_gpt, bi_columns):\n",
    "        self.df = df\n",
    "        self.bi_gpt = bi_gpt\n",
    "        self.bi_columns = bi_columns\n",
    "\n",
    "    def visualize(self):\n",
    "        with PdfPages('Bi_variate_output.pdf') as pdf:\n",
    "            for column_pair_dict in self.bi_columns:\n",
    "                for column_pair in column_pair_dict.items():\n",
    "                    fig, axs = plt.subplots(2, 1, figsize=(6, 4))\n",
    "                    column1, column2 = column_pair\n",
    "                    print(f\"Processing columns: {column1}, {column2}\")  # Debug print\n",
    "                    if pd.api.types.is_numeric_dtype(self.df[column1]) and pd.api.types.is_numeric_dtype(self.df[column2]):\n",
    "                        print(f\"Creating scatterplot for {column1} and {column2}\")  # Debug print\n",
    "                        sns.scatterplot(data=self.df, x=column1, y=column2, ax=axs[0])\n",
    "                        axs[0].set_title(f\"Relationship between {column1} and {column2}\")\n",
    "                    elif pd.api.types.is_numeric_dtype(self.df[column1]) and pd.api.types.is_categorical_dtype(self.df[column2]):\n",
    "                        print(f\"Creating boxplot for {column1} (numeric) and {column2} (categorical)\")  # Debug print\n",
    "                        sns.boxplot(x=column2, y=column1, data=self.df, ax=axs[0])\n",
    "                        axs[0].set_title(f\"Relationship between {column1} (numeric) and {column2} (categorical)\")\n",
    "                    elif pd.api.types.is_categorical_dtype(self.df[column1]) and pd.api.types.is_numeric_dtype(self.df[column2]):\n",
    "                        print(f\"Creating boxplot for {column1} (categorical) and {column2} (numeric)\")  # Debug print\n",
    "                        sns.boxplot(x=column1, y=column2, data=self.df, ax=axs[0])\n",
    "                        axs[0].set_title(f\"Relationship between {column1} (categorical) and {column2} (numeric)\")\n",
    "                    else:\n",
    "                        print(f\"Creating countplot for {column1} and {column2} (both categorical)\")  # Debug print\n",
    "                        sns.countplot(x=column1, hue=column2, data=self.df, ax=axs[0])\n",
    "                        axs[0].set_title(f\"Relationship between {column1} and {column2} (both categorical)\")\n",
    "\n",
    "                    axs[1].text(0.5, 0.5, self.bi_gpt[(column1, column2)], wrap=True, horizontalalignment='center', verticalalignment='center', fontsize=8)\n",
    "                    axs[1].axis('off')  # Hide the axes\n",
    "\n",
    "                    pdf.savefig(fig)  # saves the current figure into a pdf page\n",
    "                    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tkcalendar import DateEntry\n",
    "from datetime import datetime, time\n",
    "\n",
    "def calculate():\n",
    "    try:\n",
    "        principal = float(principal_entry.get())\n",
    "        rate = float(rate_entry.get())  # This is a monthly rate\n",
    "        date = datetime.combine(date_entry.get_date(), time.min)\n",
    "        end_date = datetime.now()  # get current date and time\n",
    "        total_days = (end_date - date).days\n",
    "\n",
    "        years = total_days // 365\n",
    "        remaining_days = total_days % 365\n",
    "        months = remaining_days // 30\n",
    "        days = remaining_days % 30\n",
    "\n",
    "        amount = principal\n",
    "        for i in range(years):\n",
    "            yearly_interest = 0\n",
    "            for j in range(12):  # calculate interest for each month in a year\n",
    "                yearly_interest += amount * rate / 100\n",
    "            amount += yearly_interest  # add the yearly interest to the principal\n",
    "            print(f\"The amount after {i+1} years is {amount}\")\n",
    "\n",
    "        if months > 0:\n",
    "            monthly_interest = amount * rate / 100 * months  # calculate interest for remaining months\n",
    "            amount += monthly_interest\n",
    "\n",
    "        if days > 0:\n",
    "            daily_interest = amount * rate / 100 / 30 * days  # calculate interest for remaining days\n",
    "            amount += daily_interest\n",
    "\n",
    "        print(f\"The amount after {years} years, {months} months and {days} days is {amount}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", str(e))\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "principal_label = tk.Label(root, text=\"Principal:\")\n",
    "principal_label.pack()\n",
    "principal_entry = tk.Entry(root)\n",
    "principal_entry.pack()\n",
    "\n",
    "rate_label = tk.Label(root, text=\"Monthly Interest Rate (%):\")\n",
    "rate_label.pack()\n",
    "rate_entry = tk.Entry(root)\n",
    "rate_entry.pack()\n",
    "\n",
    "date_label = tk.Label(root, text=\"Date:\")\n",
    "date_label.pack()\n",
    "date_entry = DateEntry(root)\n",
    "date_entry.pack()\n",
    "\n",
    "calculate_button = tk.Button(root, text=\"Calculate\", command=calculate)\n",
    "calculate_button.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from datetime import datetime, time\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        try:\n",
    "            principal = float(request.form.get('principal'))\n",
    "            rate = float(request.form.get('rate'))  # This is a monthly rate\n",
    "            date = datetime.strptime(request.form.get('date'), '%Y-%m-%d')\n",
    "            end_date = datetime.now()  # get current date and time\n",
    "            total_days = (end_date - date).days\n",
    "\n",
    "            years = total_days // 365\n",
    "            remaining_days = total_days % 365\n",
    "            months = remaining_days // 30\n",
    "            days = remaining_days % 30\n",
    "\n",
    "            amount = principal\n",
    "            for i in range(years):\n",
    "                yearly_interest = 0\n",
    "                for j in range(12):  # calculate interest for each month in a year\n",
    "                    yearly_interest += amount * rate / 100\n",
    "                amount += yearly_interest  # add the yearly interest to the principal\n",
    "\n",
    "            if months > 0:\n",
    "                monthly_interest = amount * rate / 100 * months  # calculate interest for remaining months\n",
    "                amount += monthly_interest\n",
    "\n",
    "            if days > 0:\n",
    "                daily_interest = amount * rate / 100 / 30 * days  # calculate interest for remaining days\n",
    "                amount += daily_interest\n",
    "\n",
    "            result = f\"The amount after {years} years, {months} months and {days} days is {amount}\"\n",
    "            return render_template('index.html', result=result)\n",
    "\n",
    "        except Exception as e:\n",
    "            return render_template('index.html', error=str(e))\n",
    "\n",
    "    return render_template('index.html')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Flask '__main__'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [15/Apr/2024 06:15:15] \"GET / HTTP/1.1\" 500 -\n",
      "Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\werkzeug\\serving.py\", line 333, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\werkzeug\\serving.py\", line 320, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 2551, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 2531, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 2528, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1825, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\Anuj Kesharwani\\AppData\\Local\\Temp\\ipykernel_14228\\2938513350.py\", line 42, in index\n",
      "    return render_template('index.html')\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\templating.py\", line 146, in render_template\n",
      "    template = app.jinja_env.get_or_select_template(template_name_or_list)\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jinja2\\environment.py\", line 1081, in get_or_select_template\n",
      "    return self.get_template(template_name_or_list, parent, globals)\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jinja2\\environment.py\", line 1010, in get_template\n",
      "    return self._load_template(name, globals)\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jinja2\\environment.py\", line 969, in _load_template\n",
      "    template = self.loader.load(self, name, self.make_globals(globals))\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\jinja2\\loaders.py\", line 126, in load\n",
      "    source, filename, uptodate = self.get_source(environment, name)\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\templating.py\", line 62, in get_source\n",
      "    return self._get_source_fast(environment, template)\n",
      "  File \"c:\\Users\\Anuj Kesharwani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\templating.py\", line 98, in _get_source_fast\n",
      "    raise TemplateNotFound(template)\n",
      "jinja2.exceptions.TemplateNotFound: index.html\n",
      "127.0.0.1 - - [15/Apr/2024 06:15:16] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from threading import Timer\n",
    "from werkzeug.serving import run_simple\n",
    "\n",
    "def run_in_background(app):\n",
    "    Timer(1, lambda: run_simple('localhost', 5000, app)).start()\n",
    "    return app\n",
    "\n",
    "run_in_background(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
